{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolving\n",
    "\n",
    "I have a 32 x 32 x 3 image. \n",
    "Where $w^{T}$ is the kernal, and $x_{i}$ is the position at the kernal. \n",
    "$z_{i} = w^{T} x_{i} + b $ is the convolved value for the output pixel value at the position of i. \n",
    "\n",
    "Note that the kernel can be more than 2d. It can be volumetric if there are several images to convolve into a single pixel value. if the kernel is 2x2, , the first pixel will be the 4 pixels in the image at the corner. By moving the kernel from left to right and up to down, we can receive multiple pixel values that form a convolved image for one filter. \n",
    "\n",
    "- The kernel moves according to a stride value. (e.g. (2,2))\n",
    "- A padding may be used to ensure that the next output layer's size does not get small too quickly as corner pixel is only used once. Therefore, the original image, has an extra layer of pixel=0 all around the edges. A padding=(1,2) means that there is an extra 1 layer of pixel=0 for the height, and 2 layers for the width. \n",
    "    ```\n",
    "    000000000\n",
    "    000+++000 \n",
    "    000+++000\n",
    "    000+++000\n",
    "    000000000\n",
    "    ```\n",
    "- stride and padding values do not need to be tuples and can be integers. In which case, the height and width values are the same\n",
    "\n",
    "\n",
    "You may additionally apply a sigmoid activation (or other) to the pixel values. This allows you to detect certain features in an image. \n",
    "\n",
    "Thereafter, you can use multiple kernels to get multiple outputs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolving the OOP-based\n",
    "\n",
    "import torch\n",
    "import torch.nn\n",
    "\n",
    "image=torch.rand(16,3,32,32)\n",
    "conv_filter = torch.nn.Conv2d(in_channels=3,\n",
    "                              out_channels=1, kernel_size=5,\n",
    "                              stride=1,\n",
    "                              padding=0)\n",
    "output_feature=conv_filter(image)\n",
    "print(output_feature.shape) # torch.Size([16,1,28,28])\n",
    "\n",
    "\n",
    "# Create 10 random images of shape (1, 28, 28)\n",
    "images = torch.rand(10, 1, 28, 28)\n",
    "\n",
    "# Build 6 conv. filters\n",
    "conv_filters = torch.nn.Conv2d(in_channels=1, out_channels=6, kernel_size=3, stride=1, padding=1)\n",
    "\n",
    "# Convolve the image with the filters \n",
    "output_feature = conv_filters(images)\n",
    "print(output_feature.shape) # torch.Size([10, 6, 28, 28])\n",
    "# Output_height = (height + padding__top + padding_bottom - kernel_height) / (stride) + 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convolving the functional way\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "image=torch.rand(16,3,32,32)\n",
    "filter = torch.rand(1,3,5,5) # num_images=1, num_channels=3, kernelHeight=5, kernelWidth=5\n",
    "out_feat_F = F.conv2d(image, filter, stride=1, padding=0) # NOT conv2d =/= Conv2d\n",
    "print(out_feat_F.shape) # torch.Size([16,1,28,28])\n",
    "\n",
    "# Create 10 random images\n",
    "image = torch.rand(10, 1, 28, 28)\n",
    "\n",
    "# Create 6 filters\n",
    "filters = torch.rand(6, 1, 3, 3) \n",
    "\n",
    "# Convolve the image with the filters\n",
    "output_feature = F.conv2d(image, filters, stride=1, padding=1)\n",
    "print(output_feature.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
